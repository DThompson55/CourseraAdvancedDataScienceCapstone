{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL on Weather Data\n",
    "\n",
    "This is farily experimental. Here I keep playing with Weather Data, iterating with visualizations and other parts until I have some clean data to work with. In the end only the Daily Data made much sense. Even so, I kept the rest of the data in case I might use it in other projects later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('csvs/1746061.csv', parse_dates = [1], dtype={19: 'str', 30: 'str', 31: 'str', 33: 'str', 34: 'str', 41: 'str', 42: 'str', 43: 'str', 49: 'str', 51: 'str', 58: 'str', 69: 'str', 71: 'str', 75: 'str', 88: 'str', 89: 'str'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = pd.read_csv('~/Downloads/1746061.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate Hourly, Daily, Monthly\n",
    "\n",
    "The first step is to separate data, using just the columns required for that row type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "always = [\"DATE\", \"REPORT_TYPE\", \"SOURCE\"]\n",
    "always = [\"DATE\"]\n",
    "\n",
    "monthly = always+[\"AWND\", \"CDSD\", \"CLDD\", \"DSNW\",  \"MonthlyGreatestPrecip\", \"MonthlyGreatestPrecipDate\", \"MonthlyGreatestSnowDepth\", \"MonthlyGreatestSnowDepthDate\", \"MonthlyGreatestSnowfall\", \"MonthlyGreatestSnowfallDate\", \"MonthlyMaxSeaLevelPressureValue\", \"MonthlyMaxSeaLevelPressureValueDate\", \"MonthlyMaxSeaLevelPressureValueTime\", \"MonthlyMaximumTemperature\", \"MonthlyMeanTemperature\", \"MonthlyMinSeaLevelPressureValue\", \"MonthlyMinSeaLevelPressureValueDate\", \"MonthlyMinSeaLevelPressureValueTime\", \"MonthlyMinimumTemperature\", \"MonthlySeaLevelPressure\", \"MonthlyStationPressure\", \"MonthlyTotalLiquidPrecipitation\", \"MonthlyTotalSnowfall\", \"MonthlyWetBulb\", \"NormalsCoolingDegreeDay\", \"NormalsHeatingDegreeDay\"]\n",
    "daily = always+[\"DailyAverageDewPointTemperature\", \"DailyAverageDryBulbTemperature\", \"DailyAverageRelativeHumidity\", \"DailyAverageSeaLevelPressure\", \"DailyAverageStationPressure\", \"DailyAverageWetBulbTemperature\", \"DailyAverageWindSpeed\", \"DailyCoolingDegreeDays\", \"DailyDepartureFromNormalAverageTemperature\", \"DailyHeatingDegreeDays\", \"DailyMaximumDryBulbTemperature\", \"DailyMinimumDryBulbTemperature\", \"DailyPeakWindDirection\", \"DailyPeakWindSpeed\", \"DailyPrecipitation\", \"DailySnowDepth\", \"DailySnowfall\", \"DailySustainedWindDirection\", \"DailySustainedWindSpeed\", \"Sunrise\", \"Sunset\"]\n",
    "daily = always+[\"DailyAverageDryBulbTemperature\", \"DailyPeakWindSpeed\", \"DailyPrecipitation\", \"DailySnowDepth\", \"DailySnowfall\", \"Sunrise\", \"Sunset\"]\n",
    "hourly = always+[\"HourlyAltimeterSetting\", \"HourlyDewPointTemperature\", \"HourlyDryBulbTemperature\", \"HourlyPressureTendency\", \"HourlyRelativeHumidity\", \"HourlySeaLevelPressure\", \"HourlyStationPressure\", \"HourlyVisibility\", \"HourlyWetBulbTemperature\", \"HourlyWindDirection\"]\n",
    "hourly = always+[\"HourlyPrecipitation\", \"HourlyPresentWeatherType\", \"HourlySkyConditions\", \"HourlyWindSpeed\"]\n",
    "drop_cols = [\"STATION\", \"ShortDurationEndDate010\", \"ShortDurationEndDate015\", \"ShortDurationEndDate020\", \"ShortDurationEndDate030\", \"ShortDurationEndDate045\", \"ShortDurationEndDate060\", \"ShortDurationEndDate080\", \"ShortDurationEndDate100\", \"ShortDurationEndDate120\", \"ShortDurationEndDate150\", \"ShortDurationEndDate180\", \"ShortDurationPrecipitationValue005\", \"ShortDurationPrecipitationValue010\", \"ShortDurationPrecipitationValue015\", \"ShortDurationPrecipitationValue020\", \"ShortDurationPrecipitationValue030\", \"ShortDurationPrecipitationValue045\", \"ShortDurationPrecipitationValue060\", \"ShortDurationPrecipitationValue080\", \"ShortDurationPrecipitationValue100\", \"ShortDurationPrecipitationValue120\", \"ShortDurationPrecipitationValue150\", \"ShortDurationPrecipitationValue180\", \"TStorms\", \"WindEquipmentChangeDate\", \"BackupDirection\", \"BackupDistance\", \"BackupDistanceUnit\", \"BackupElements\", \"BackupElevation\", \"BackupElevationUnit\", \"BackupEquipment\", \"BackupLatitude\", \"BackupLongitude\", \"BackupName\"]\n",
    "never = [\"BackupDirection\", \"BackupDistance\", \"BackupDistanceUnit\", \"BackupElements\", \"BackupElevation\", \"BackupElevationUnit\", \"BackupEquipment\", \"BackupLatitude\", \"BackupLongitude\", \"BackupName\"]\n",
    "never = never + drop_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FM-15', 'SOD  ', 'FM-16', 'SOM  '], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"REPORT_TYPE\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51010, 88)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.drop(columns=never, inplace=True)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily = df1.loc[lambda df: df.REPORT_TYPE == \"SOD  \", :][daily]\n",
    "df_16 = df1.loc[lambda df: df.REPORT_TYPE == \"FM-16\", :][hourly]\n",
    "df_15 = df1.loc[lambda df: df.REPORT_TYPE == \"FM-15\", :][hourly]\n",
    "df_hourly = pd.concat([df_15, df_16])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '0.01', '0.04', '0.07', '0.06', '0.05', '0.12', '0.11',\n",
       "       '0.03', '0.15', 'T', '0.02', '0.09', '0.17', '0.28', '0.24',\n",
       "       '0.23', '0.31', '0.29', '0.16', '0.14', '0.19', '0.08', '0.1',\n",
       "       '0.01s', '0.13', nan, '0.05s', '0.04s', '0.18', '0.03s', '0.26',\n",
       "       '0.4', '0.97', '0.06s', '0.02s', '0.16s', '0.25', '0.21', '0.39s',\n",
       "       '0.37', '0.36', '1.28', '0.41', '0.22', '0.09s', '0.60s', '0.3',\n",
       "       '0.2', '0.79', '0.11s', '0.63', '0.34', '0.27', '0.46', '0.58',\n",
       "       '0.14s', '0.81s', '0.32', '0.17s', '0.47', '0.44', '0.39', '0.45',\n",
       "       '0.62', '0.28s', '0.59', '0.82', '0.5', '0.54', '0.42', '0.43s',\n",
       "       '0.57', '0.61', '1.15', '0.38', '0.67', '0.33s', '0.52', '0.45s',\n",
       "       '0.96s', '0.55', '0.43', '0.69', '0.10s', '0.35', '0.68', '0.08s',\n",
       "       '1.12', '0.86', '0.33', '1.69', '0.73', '0.7', '0.87', '0.50s',\n",
       "       '0.29s', '0.07s', '0.41s', '1.13', '0.74', '0.51', '1.21', '1.22',\n",
       "       '0.99', '1', '1.08', '1.55', '1.57', '0.64', '0.71', '0.72',\n",
       "       '0.89'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hourly.HourlyPrecipitation.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hourly Data\n",
    "\n",
    "Try to locate the weather types. Later on we might make a one-hot encoding out of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather Types are  [nan 'SN' 'RA' 'BR' 'HZ' 'UP' 'FZRA' 'FG']\n"
     ]
    }
   ],
   "source": [
    "#df_hourly[\"x1\"] = df_hourly.HourlyPresentWeatherType.str.replace(\"[^A-Z ]\", \"\", case=True, flags=0, regex=True).apply(lambda x: (list(set(x.split()))) if (isinstance(x, str) ) else np.NaN)\n",
    "df_hourly[\"x1\"] = df_hourly.HourlyPresentWeatherType.str.replace(\"[^A-Z ]\", \"\", case=True, flags=0, regex=True).apply(lambda x: x.split() if (isinstance(x, str) ) else np.NaN)\n",
    "df_hourly[\"x2\"] = df_hourly.x1.apply(lambda x: x[-1] if (( isinstance(x, list) ) ) else np.NaN)\n",
    "\n",
    "print(\"Weather Types are \", (df_hourly[\"x2\"].unique()))\n",
    "\n",
    "#df_hourly[\"x3\"] = df_hourly.x1.apply(lambda x: x[1] if (( isinstance(x, list) and len(x) > 1 ) ) else np.NaN)\n",
    "df_hourly = pd.get_dummies(df_hourly, prefix=None, columns = [\"x2\"])\n",
    "df_hourly.rename(index=str, inplace=True, columns={\"x2_BR\": \"BR\", \"x2_FG\": \"FG\", \"x2_FZ\": \"FZ\", \"x2_HZ\": \"HZ\", \"x2_RA\": \"RA\", \"x2_SN\": \"SN\", \"x2_UP\": \"UP\", \"x2_FU\": \"FU\", \"x2_FZRA\": \"FZRA\"})\n",
    "\n",
    "df_hourly.HourlyPrecipitation = pd.to_numeric(df_hourly.HourlyPrecipitation.str.replace(\"[A-Z]\", \"\", case=False, flags=0, regex=True))\n",
    "df_hourly = df_hourly.fillna(0)\n",
    "\n",
    "\n",
    "#df_hourly[\"x4\"].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly = df_hourly.drop(columns=[\"HourlyPresentWeatherType\",\"HourlySkyConditions\",\"x1\" ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly.to_csv(\"csvs/hourly_weather_nyc.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily Data\n",
    "\n",
    "There are a lot of gaps in the daily data, and just some strange special characters. One cleanup routine helps across all of the daily data rollups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(x):\n",
    "    #print(\"A1\",x.unique())\n",
    "    x  = x.str.replace(\"[A-Z]\", \"\", case=False, flags=0, regex=True)\n",
    "    #print(\"A2\",x.unique())\n",
    "    x  = x.str.replace(\"*\", \"\", case=False, flags=0, regex=False)\n",
    "    #print(\"A3\",x.unique())\n",
    "    x  = pd.to_numeric(x)\n",
    "     #x.astype(int)\n",
    "    #print(\"B\",x.unique())\n",
    "  \n",
    "    return x\n",
    "#df_daily[df_daily['DailySnowDepth'].str.match(\"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>DailyAverageDryBulbTemperature</th>\n",
       "      <th>DailyPeakWindSpeed</th>\n",
       "      <th>DailyPrecipitation</th>\n",
       "      <th>DailySnowDepth</th>\n",
       "      <th>DailySnowfall</th>\n",
       "      <th>Sunrise</th>\n",
       "      <th>Sunset</th>\n",
       "      <th>DailyAverageDryBulbTemperature2</th>\n",
       "      <th>DailyPeakWindSpeed2</th>\n",
       "      <th>DailyPrecipitation2</th>\n",
       "      <th>DailySnowDepth2</th>\n",
       "      <th>DailySnowfall2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2015-01-01 23:59:00</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1639.0</td>\n",
       "      <td>33</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2015-01-02 23:59:00</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>39</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2015-01-03 23:59:00</td>\n",
       "      <td>38</td>\n",
       "      <td>18</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1641.0</td>\n",
       "      <td>38</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2015-01-04 23:59:00</td>\n",
       "      <td>49</td>\n",
       "      <td>46</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1642.0</td>\n",
       "      <td>49</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2015-01-05 23:59:00</td>\n",
       "      <td>35</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>35</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   DATE DailyAverageDryBulbTemperature DailyPeakWindSpeed  \\\n",
       "24  2015-01-01 23:59:00                             33                 31   \n",
       "49  2015-01-02 23:59:00                             39                 25   \n",
       "109 2015-01-03 23:59:00                             38                 18   \n",
       "161 2015-01-04 23:59:00                             49                 46   \n",
       "186 2015-01-05 23:59:00                             35                 38   \n",
       "\n",
       "    DailyPrecipitation DailySnowDepth DailySnowfall  Sunrise  Sunset  \\\n",
       "24                   0              0             0    720.0  1639.0   \n",
       "49                   0              0             0    720.0  1640.0   \n",
       "109               0.71              0             T    720.0  1641.0   \n",
       "161                0.3              0             0    720.0  1642.0   \n",
       "186                  0              0             0    720.0  1643.0   \n",
       "\n",
       "     DailyAverageDryBulbTemperature2  DailyPeakWindSpeed2  \\\n",
       "24                                33                 31.0   \n",
       "49                                39                 25.0   \n",
       "109                               38                 18.0   \n",
       "161                               49                 46.0   \n",
       "186                               35                 38.0   \n",
       "\n",
       "     DailyPrecipitation2  DailySnowDepth2  DailySnowfall2  \n",
       "24                  0.00              0.0             0.0  \n",
       "49                  0.00              0.0             0.0  \n",
       "109                 0.71              0.0             0.0  \n",
       "161                 0.30              0.0             0.0  \n",
       "186                 0.00              0.0             0.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_daily['DailyAverageDryBulbTemperature2'] = cleanup(df_daily.DailyAverageDryBulbTemperature)\n",
    "df_daily['DailyPeakWindSpeed2'] = cleanup(df_daily.DailyPeakWindSpeed)\n",
    "df_daily['DailyPrecipitation2'] = cleanup(df_daily.DailyPrecipitation)\n",
    "df_daily['DailySnowDepth2'] = cleanup(df_daily.DailySnowDepth)\n",
    "df_daily['DailySnowfall2'] = cleanup(df_daily.DailySnowfall)\n",
    "df_daily = df_daily.fillna(0)\n",
    "\n",
    "df_daily.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wind Speed\n",
    "\n",
    "Wind Speed is broken in many places. 2,237 miles per hour? We'll need to fix that later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  31.,   25.,   18.,   46.,   38.,   24.,   39.,   30.,   20.,\n",
       "         17.,   32.,   23.,   33.,   15.,   22.,   19.,   34.,   36.,\n",
       "         44.,   27.,   26.,   29.,   28.,   37.,   42.,   16.,   21.,\n",
       "         41.,   43.,   35.,   13.,   11.,   14.,   12., 2237.,    0.,\n",
       "         40.,   45.,   10.,   47.,   48.,    9.,    7.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_daily['DailyPeakWindSpeed2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily = df_daily.drop(columns=[\"DailyAverageDryBulbTemperature\",\"DailyPeakWindSpeed\",\"DailyPrecipitation\",\"DailySnowDepth\",\"DailySnowfall\" ])\n",
    "\n",
    "df_daily.rename(index=str, inplace=True, columns={\"DailyAverageDryBulbTemperature2\":\"DailyAverageDryBulbTemperature\", \"DailyPeakWindSpeed2\":\"DailyPeakWindSpeed\", \"DailyPrecipitation2\":\"DailyPrecipitation\", \"DailySnowDepth2\":\"DailySnowDepth\", \"DailySnowfall2\":\"DailySnowfall\"})\n",
    "\n",
    "\n",
    "print(\"Cleaned up Daily\")\n",
    "df_daily.to_csv(\"csvs/daily_weather_nyc.csv\")\n",
    "df_daily.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
